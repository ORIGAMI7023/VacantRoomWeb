#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
VacantRoomWeb é¡¹ç›®ä»£ç æ‰“åŒ…è„šæœ¬
ç”¨äºç”Ÿæˆé€‚åˆä¸Šä¼ åˆ°Claudeçš„æˆ¿é—´ç®¡ç†ç³»ç»Ÿä»£ç æ–‡æ¡£
âœ¨ åŒ…å«æ•æ„Ÿä¿¡æ¯ä¿æŠ¤åŠŸèƒ½
"""

import os
import glob
import json
import re
from pathlib import Path
from datetime import datetime

# âœ¨å¢å¼ºçš„æ©ç å‡½æ•°
def mask_value(val: str, min_show: int = None) -> str:
    """
    æ ¹æ®å­—ç¬¦ä¸²é•¿åº¦æ™ºèƒ½æ©ç 
    - çŸ­å€¼ï¼ˆâ‰¤8å­—ç¬¦ï¼‰ï¼šæ˜¾ç¤ºå‰4ä½ + ****
    - ä¸­ç­‰å€¼ï¼ˆ9-16å­—ç¬¦ï¼‰ï¼šæ˜¾ç¤ºå‰8ä½ + ****
    - é•¿å€¼ï¼ˆ>16å­—ç¬¦ï¼‰ï¼šæ˜¾ç¤ºå‰16ä½ + ****
    """
    if not val:
        return val
    
    if min_show is not None:
        show_chars = min_show
    elif len(val) <= 8:
        show_chars = min(4, len(val))
    elif len(val) <= 16:
        show_chars = 8
    else:
        show_chars = 16
    
    if len(val) <= show_chars:
        return val
    return val[:show_chars] + '****'

# âœ¨æ•æ„Ÿä¿¡æ¯å…³é”®è¯åˆ—è¡¨
SENSITIVE_KEYWORDS = [
    'password', 'pwd', 'passwd', 'secret', 'key', 'token', 'apikey', 'api_key',
    'connectionstring', 'connstr', 'connection_string', 'hash', 'salt', 
    'signature', 'private', 'credential', 'auth', 'jwt', 'bearer',
    'database', 'server', 'userid', 'user_id', 'username', 'admin'
]

def is_sensitive_key(key: str) -> bool:
    """æ£€æŸ¥é”®åæ˜¯å¦åŒ…å«æ•æ„Ÿå…³é”®è¯"""
    key_lower = key.lower()
    return any(keyword in key_lower for keyword in SENSITIVE_KEYWORDS)

def mask_connection_string(conn_str: str) -> str:
    """æ™ºèƒ½å¤„ç†è¿æ¥å­—ç¬¦ä¸²ï¼Œåªæ©ç æ•æ„Ÿéƒ¨åˆ†"""
    if not conn_str:
        return conn_str
    
    # å¤„ç†å„ç§è¿æ¥å­—ç¬¦ä¸²æ ¼å¼
    patterns = [
        (r'(password|pwd)\s*=\s*([^;]+)', r'\1=****'),
        (r'(user\s*id|uid|username)\s*=\s*([^;]+)', lambda m: f'{m.group(1)}={mask_value(m.group(2), 4)}'),
        (r'(server|data\s*source)\s*=\s*([^;]+)', lambda m: f'{m.group(1)}={mask_value(m.group(2), 8)}'),
    ]
    
    result = conn_str
    for pattern, replacement in patterns:
        if callable(replacement):
            result = re.sub(pattern, replacement, result, flags=re.IGNORECASE)
        else:
            result = re.sub(pattern, replacement, result, flags=re.IGNORECASE)
    
    return result

def process_json_content(content: str) -> str:
    """å¤„ç†JSONæ–‡ä»¶ä¸­çš„æ•æ„Ÿä¿¡æ¯"""
    try:
        data = json.loads(content)
        processed_data = mask_json_recursive(data)
        return json.dumps(processed_data, indent=2, ensure_ascii=False)
    except json.JSONDecodeError:
        return content

def mask_json_recursive(obj):
    """é€’å½’å¤„ç†JSONå¯¹è±¡ä¸­çš„æ•æ„Ÿä¿¡æ¯"""
    if isinstance(obj, dict):
        result = {}
        for key, value in obj.items():
            if isinstance(value, str) and is_sensitive_key(key):
                # ç‰¹æ®Šå¤„ç†è¿æ¥å­—ç¬¦ä¸²
                if 'connection' in key.lower():
                    result[key] = mask_connection_string(value)
                else:
                    result[key] = mask_value(value)
            elif isinstance(value, (dict, list)):
                result[key] = mask_json_recursive(value)
            else:
                result[key] = value
        return result
    elif isinstance(obj, list):
        return [mask_json_recursive(item) for item in obj]
    else:
        return obj

def process_csharp_content(content: str) -> str:
    """å¤„ç†C#ä»£ç ä¸­çš„æ•æ„Ÿä¿¡æ¯"""
    lines = content.split('\n')
    processed_lines = []
    
    for line in lines:
        # å¤„ç†å­—ç¬¦ä¸²å­—é¢é‡èµ‹å€¼
        # å¦‚: string password = "secret123";
        string_assignment_pattern = r'(\w*(?:' + '|'.join(SENSITIVE_KEYWORDS) + r')\w*)\s*=\s*["\']([^"\']+)["\']'
        
        def replace_assignment(match):
            var_name, value = match.groups()
            if is_sensitive_key(var_name):
                return f'{var_name} = "{mask_value(value)}"'
            return match.group(0)
        
        processed_line = re.sub(string_assignment_pattern, replace_assignment, line, flags=re.IGNORECASE)
        
        # å¤„ç†å¸¸é‡å®šä¹‰
        # å¦‚: const string API_KEY = "abc123";
        const_pattern = r'(const\s+string\s+\w*(?:' + '|'.join(SENSITIVE_KEYWORDS) + r')\w*\s*=\s*["\'])([^"\']+)(["\'])'
        
        def replace_const(match):
            prefix, value, suffix = match.groups()
            return f'{prefix}{mask_value(value)}{suffix}'
        
        processed_line = re.sub(const_pattern, replace_const, processed_line, flags=re.IGNORECASE)
        
        # å¤„ç†é…ç½®è®¿é—®
        # å¦‚: Configuration["ConnectionStrings:Default"]
        config_pattern = r'(Configuration\[["\'][^"\']*(?:' + '|'.join(SENSITIVE_KEYWORDS) + r')[^"\']*["\']]\s*=\s*["\'])([^"\']+)(["\'])'
        
        def replace_config(match):
            prefix, value, suffix = match.groups()
            return f'{prefix}{mask_value(value)}{suffix}'
        
        processed_line = re.sub(config_pattern, replace_config, processed_line, flags=re.IGNORECASE)
        
        processed_lines.append(processed_line)
    
    return '\n'.join(processed_lines)

def process_config_content(content: str) -> str:
    """å¤„ç†å…¶ä»–é…ç½®æ–‡ä»¶ä¸­çš„æ•æ„Ÿä¿¡æ¯"""
    # å¤„ç† key=value æ ¼å¼
    lines = content.split('\n')
    processed_lines = []
    
    for line in lines:
        # åŒ¹é… key=value æˆ– key:value æ ¼å¼
        kv_pattern = r'^(\s*)([^=:]+)[=:](.+)$'
        match = re.match(kv_pattern, line.strip())
        
        if match:
            indent, key, value = match.groups()
            if is_sensitive_key(key.strip()):
                processed_line = f'{indent}{key.strip()}={mask_value(value.strip())}'
            else:
                processed_line = line
        else:
            processed_line = line
        
        processed_lines.append(processed_line)
    
    return '\n'.join(processed_lines)

def process_file_content(file_path: str, content: str) -> str:
    """æ ¹æ®æ–‡ä»¶ç±»å‹å¤„ç†æ•æ„Ÿä¿¡æ¯"""
    file_ext = os.path.splitext(file_path)[1].lower()
    file_name = os.path.basename(file_path).lower()
    
    if file_ext == '.json':
        # å¤„ç† JSON é…ç½®æ–‡ä»¶
        return process_json_content(content)
    elif file_ext == '.cs':
        # å¤„ç† C# ä»£ç æ–‡ä»¶
        return process_csharp_content(content)
    elif file_ext in ['.config', '.xml'] and ('web.config' in file_name or 'app.config' in file_name):
        # å¤„ç† XML é…ç½®æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
        def replacer(m):
            name, val = m.group(1), m.group(2)
            return f'<environmentVariable name="{name}" value="{mask_value(val)}" />'
        
        # å¤„ç†ç¯å¢ƒå˜é‡
        pattern = re.compile(r'<environmentVariable\s+name="([^"]+)"\s+value="([^"]+)"\s*/>')
        content = pattern.sub(replacer, content)
        
        # å¤„ç†å…¶ä»–é…ç½®é¡¹
        content = process_config_content(content)
        
        return content
    elif file_ext in ['.properties', '.ini', '.env']:
        # å¤„ç†å…¶ä»–é…ç½®æ–‡ä»¶æ ¼å¼
        return process_config_content(content)
    else:
        return content

def get_file_size_from_bytes(size_bytes):
    """å°†å­—èŠ‚æ•°è½¬æ¢ä¸ºäººç±»å¯è¯»æ ¼å¼"""
    if size_bytes < 1024:
        return f"{size_bytes} B"
    elif size_bytes < 1024 * 1024:
        return f"{size_bytes/1024:.1f} KB"
    else:
        return f"{size_bytes/(1024*1024):.1f} MB"

def get_file_extension_for_syntax(file_path):
    """æ ¹æ®æ–‡ä»¶è·¯å¾„è¿”å›è¯­æ³•é«˜äº®çš„è¯­è¨€æ ‡è¯†"""
    ext = os.path.splitext(file_path)[1].lower()
    
    syntax_map = {
        '.cs': 'csharp',
        '.razor': 'razor',
        '.css': 'css',
        '.js': 'javascript',
        '.json': 'json',
        '.csproj': 'xml',
        '.config': 'xml',
        '.xml': 'xml',
        '.md': 'markdown',
        '.txt': 'text'
    }
    
    return syntax_map.get(ext, 'text')

def should_skip_file(filename):
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡æ–‡ä»¶"""
    skip_patterns = [
        ".tmp", ".temp", ".bak", ".old", ".user", ".suo", ".cache",
        ".dll", ".exe", ".pdb", ".deps.json"
    ]
    
    skip_files = [
        "bootstrap.min.css",
        "bootstrap.min.css.map"
    ]
    
    # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
    for pattern in skip_patterns:
        if filename.lower().endswith(pattern):
            return True
    
    # æ£€æŸ¥ç‰¹å®šæ–‡ä»¶å
    if filename in skip_files:
        return True
        
    return False

def get_target_folders():
    """è·å–éœ€è¦æ‰«æçš„ç›®æ ‡æ–‡ä»¶å¤¹"""
    return [
        "Components", 
        "Pages", 
        "Layout",
        "Services",
        "Data",
        "Models",
        "Controllers",
        "Middleware",
        "Extensions",
        "Utils",
        "Helpers",
        "wwwroot",
        "Properties"
    ]

def combine_code_files():
    # Base directory of your project
    base_dir = r"D:\Programing\C#\VacantRoomWeb\VacantRoomWeb"

    # Output text file
    output_file = os.path.join(r"D:\Programing\C#\VacantRoomWeb", "#all_code_files.txt")

    file_patterns = [
        "*.cs", "*.css", "*.razor", "*.csproj", "*.json", "*.config", "*.xml",
        "*.md", "*.txt", "Components/**/*.razor", "Components/**/*.css",
        "Pages/**/*.razor", "Layout/**/*.razor", "Layout/**/*.css",
        "Services/**/*.cs", "wwwroot/**/*.css", "wwwroot/**/*.js",
        "Properties/**/*.json", "Properties/**/*.xml",
    ]

    exclude_patterns = [
        "bin/**","obj/**",".vs/**","*.user","*.cache","*.tmp","*.log",
        "bootstrap.min.css","bootstrap.min.css.map",
        "node_modules/**","packages/**",".git/**","Logs/**","all_code_files.txt"
    ]

    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(base_dir):
        print(f"é”™è¯¯: ç›®å½•ä¸å­˜åœ¨: {base_dir}")
        print("è¯·ä¿®æ”¹è„šæœ¬ä¸­çš„ base_dir è·¯å¾„")
        
        # å°è¯•çˆ¶ç›®å½•
        parent_dir = r"D:\Programing\C#\VacantRoomWeb"
        if os.path.exists(parent_dir):
            print(f"å‘ç°çˆ¶ç›®å½•: {parent_dir}")
            print("çˆ¶ç›®å½•å†…å®¹:")
            for item in os.listdir(parent_dir):
                item_path = os.path.join(parent_dir, item)
                if os.path.isdir(item_path):
                    print(f"  ğŸ“ {item}/")
                else:
                    print(f"  ğŸ“„ {item}")
        return

    print(f"æ‰«æç›®å½•: {base_dir}")
    print(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
    
    # ç»Ÿè®¡å˜é‡
    processed_files = 0
    total_size = 0
    protected_files = 0  # âœ¨ç»Ÿè®¡è¢«ä¿æŠ¤çš„æ–‡ä»¶æ•°
    target_folders = get_target_folders()

    current_time = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")

    with open(output_file, 'w', encoding='utf-8') as outf:
        # âœ¨å†™å…¥é¡¹ç›®æè¿°
        outf.write("# VacantRoomWeb - ç©ºæˆ¿é—´ç®¡ç†ç³»ç»Ÿ\n")
        outf.write("## é¡¹ç›®æ¦‚è¿°\n")
        outf.write("åŸºäº Blazor Server çš„æˆ¿é—´ç®¡ç†ç³»ç»Ÿï¼Œæä¾›æˆ¿é—´çŠ¶æ€ç›‘æ§ã€é¢„è®¢ç®¡ç†ç­‰åŠŸèƒ½\n")
        outf.write("âš ï¸  æ•æ„Ÿä¿¡æ¯å·²è‡ªåŠ¨æ©ç å¤„ç†ï¼Œä¿æŠ¤å¯†ç ã€å¯†é’¥ã€è¿æ¥å­—ç¬¦ä¸²ç­‰\n\n")
        
        outf.write("=" * 80 + "\n")
        outf.write(f"æ‰“åŒ…æ—¶é—´: {current_time}\n")
        outf.write("VACANTROOM WEB PROJECT - ALL CODE FILES\n")
        outf.write("âš ï¸  æ•æ„Ÿä¿¡æ¯å·²è‡ªåŠ¨æ©ç å¤„ç†\n")
        outf.write("=" * 80 + "\n\n")

        original_dir = os.getcwd()
        os.chdir(base_dir)

        try:
            # âœ¨æ”¶é›†æ‰€æœ‰æ–‡ä»¶ä¿¡æ¯
            all_files = []
            folder_stats = {}  # ç»Ÿè®¡æ¯ä¸ªæ–‡ä»¶å¤¹çš„æ–‡ä»¶æ•°
            
            print("å¼€å§‹æ‰«ææ–‡ä»¶...")
            
            for pattern in file_patterns:
                matching_files = glob.glob(pattern, recursive=True)
                for file_path in matching_files:
                    if os.path.isfile(file_path):
                        normalized_path = file_path.replace('\\', '/')
                        
                        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ’é™¤
                        should_exclude = False
                        for exclude_pattern in exclude_patterns:
                            if exclude_pattern.endswith('/**'):
                                if normalized_path.startswith(exclude_pattern[:-3] + '/'):
                                    should_exclude = True
                                    break
                            elif (exclude_pattern in normalized_path or 
                                  os.path.basename(file_path) == exclude_pattern):
                                should_exclude = True
                                break
                        
                        if should_exclude or should_skip_file(os.path.basename(file_path)):
                            continue
                        
                        # ç¡®å®šæ–‡ä»¶å¤¹
                        folder_name = "æ ¹ç›®å½•"
                        for folder in target_folders:
                            if normalized_path.startswith(folder + '/'):
                                folder_name = folder
                                break
                        
                        if folder_name == "æ ¹ç›®å½•" and '/' in normalized_path:
                            continue  # è·³è¿‡ä¸åœ¨ç›®æ ‡æ–‡ä»¶å¤¹çš„æ–‡ä»¶
                        
                        file_size = os.path.getsize(file_path)
                        all_files.append({
                            'path': normalized_path,
                            'folder': folder_name,
                            'size': file_size
                        })
                        
                        # ç»Ÿè®¡æ–‡ä»¶å¤¹
                        if folder_name not in folder_stats:
                            folder_stats[folder_name] = 0
                        folder_stats[folder_name] += 1

            all_files = sorted(all_files, key=lambda x: (x['folder'], x['path']))
            
            print(f"æ‰¾åˆ° {len(all_files)} ä¸ªæ–‡ä»¶è¿›è¡Œæ‰“åŒ…")

            # âœ¨å†™å…¥æ–‡ä»¶ç´¢å¼•
            outf.write("## æ–‡ä»¶ç´¢å¼•\n")
            current_folder = ""
            for file_info in all_files:
                folder = file_info['folder']
                if folder != current_folder:
                    current_folder = folder
                    file_count = folder_stats.get(folder, 0)
                    outf.write(f"\n### {folder} ({file_count} ä¸ªæ–‡ä»¶)\n")
                
                size_str = get_file_size_from_bytes(file_info['size'])
                outf.write(f"- {file_info['path']} ({size_str})\n")

            # âœ¨å†™å…¥é¡¹ç›®ç»Ÿè®¡
            outf.write(f"\n## é¡¹ç›®ç»Ÿè®¡\n")
            outf.write(f"- æ€»æ–‡ä»¶æ•°: {len(all_files)}\n")
            outf.write(f"- æ€»å¤§å°: {get_file_size_from_bytes(sum(f['size'] for f in all_files))}\n")
            outf.write(f"- ç”Ÿæˆæ—¶é—´: {current_time}\n")
            outf.write(f"- é¡¹ç›®è·¯å¾„: {base_dir}\n")
            
            # âœ¨å†™å…¥æŠ€æœ¯æ ˆä¿¡æ¯
            outf.write(f"\n## æŠ€æœ¯æ ˆ\n")
            outf.write("- ASP.NET Core Blazor Server\n")
            outf.write("- Entity Framework Core\n")
            outf.write("- Bootstrap CSS Framework\n")
            outf.write("- SignalR (å®æ—¶é€šä¿¡)\n")
            
            # âœ¨å†™å…¥æ–‡ä»¶å¤¹ç»Ÿè®¡
            outf.write(f"\n## æ–‡ä»¶å¤¹ç»Ÿè®¡\n")
            for folder, count in sorted(folder_stats.items()):
                outf.write(f"- {folder}: {count} ä¸ªæ–‡ä»¶\n")

            # âœ¨å†™å…¥æ–‡ä»¶å†…å®¹
            outf.write("\n" + "="*80 + "\n")
            outf.write("## æ–‡ä»¶å†…å®¹\n")
            outf.write("="*80 + "\n")

            current_folder = ""
            for file_info in all_files:
                folder = file_info['folder']
                if folder != current_folder:
                    current_folder = folder
                    outf.write(f"\n\n### {folder} æ–‡ä»¶å¤¹\n")
                    outf.write("-" * 50 + "\n")

                try:
                    outf.write(f"\n#### æ–‡ä»¶: {file_info['path']}\n")
                    outf.write(f"```{get_file_extension_for_syntax(file_info['path'])}\n")
                    
                    with open(file_info['path'], 'r', encoding='utf-8', errors='ignore') as inf:
                        file_content = inf.read()
                    
                    # âœ¨å¤„ç†æ•æ„Ÿä¿¡æ¯
                    original_content = file_content
                    file_content = process_file_content(file_info['path'], file_content)
                    
                    # ç»Ÿè®¡æ˜¯å¦æœ‰æ•æ„Ÿä¿¡æ¯è¢«ä¿æŠ¤
                    if file_content != original_content:
                        protected_files += 1
                    
                    outf.write(file_content + "\n\n")
                    outf.write("```\n")
                    
                    # ç»Ÿè®¡æ–‡ä»¶å¤§å°
                    processed_files += 1
                    total_size += len(file_content.encode('utf-8'))
                    
                except Exception as e:
                    outf.write(f"[ERROR: æ— æ³•è¯»å–æ–‡ä»¶ - {str(e)}]\n```\n")
                    processed_files += 1

            # âœ¨å†™å…¥ä¿æŠ¤ç»Ÿè®¡
            outf.write("\n" + "=" * 80 + "\n")
            outf.write("ä»£ç æ–‡ä»¶ç»“æŸ\n")
            outf.write("âœ… æ•æ„Ÿä¿¡æ¯ä¿æŠ¤ï¼šå¯†ç ã€å¯†é’¥ã€è¿æ¥å­—ç¬¦ä¸²ç­‰å·²è‡ªåŠ¨æ©ç \n")
            outf.write(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼šåŒ…å«æ–‡ä»¶æ€»æ•° {processed_files} ä¸ª\n")
            outf.write(f"ğŸ”’ æ•æ„Ÿä¿¡æ¯ä¿æŠ¤ï¼š{protected_files} ä¸ªæ–‡ä»¶\n")
            outf.write("=" * 80 + "\n")

        finally:
            os.chdir(original_dir)
    
    # è®¡ç®—è¾“å‡ºæ–‡ä»¶å¤§å°å¹¶æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if os.path.exists(output_file):
        output_size = os.path.getsize(output_file)
        
        print("\n" + "=" * 60)
        print("âœ… æ‰€æœ‰æ–‡ä»¶åˆå¹¶æˆåŠŸ!")
        print(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
        print(f"æ–‡ä»¶å¤§å°: {get_file_size_from_bytes(output_size)}")
        print(f"åŒ…å«æ–‡ä»¶æ€»æ•°: {processed_files}")
        print(f"æ•æ„Ÿä¿¡æ¯ä¿æŠ¤: {protected_files} ä¸ªæ–‡ä»¶")
        print("=" * 60)
        print("\nâœ… æ‰“åŒ…å®Œæˆï¼æ•æ„Ÿä¿¡æ¯å·²è‡ªåŠ¨ä¿æŠ¤ï¼Œå¯ä»¥å®‰å…¨ä¸Šä¼ åˆ°Claudeè¿›è¡Œä»£ç åˆ†æã€‚")

if __name__ == "__main__":
    try:
        combine_code_files()
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        input()